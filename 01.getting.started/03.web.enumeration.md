# Web Enumeration

## Gobuster

Gobuster is a versatile tool that allows for performing DNS, vhost, and directory brute-forcing.

    $ gobuster dir -u http://10.10.10.121/ -w /usr/share/dirb/wordlists/common.txt

    ===============================================================
    Gobuster v3.0.1
    by OJ Reeves (@TheColonial) & Christian Mehlmauer (@_FireFart_)
    ===============================================================
    [+] Url:            http://10.10.10.121/
    [+] Threads:        10
    [+] Wordlist:       /usr/share/dirb/wordlists/common.txt
    [+] Status codes:   200,204,301,302,307,401,403
    [+] User Agent:     gobuster/3.0.1
    [+] Timeout:        10s
    ===============================================================
    2020/12/11 21:47:25 Starting gobuster
    ===============================================================
    /.hta (Status: 403)
    /.htpasswd (Status: 403)
    /.htaccess (Status: 403)
    /index.php (Status: 200)
    /server-status (Status: 403)
    /wordpress (Status: 301)
    ===============================================================
    2020/12/11 21:47:46 Finished
    ===============================================================

## DNS Subdomain Enumeration

We can use Gobuster to enumerate available subdomains of a given domain using the dns flag to specify DNS mode.

Install seclists:

    $ sudo apt install seclists -y

Enumerate subdomains:

    $ gobuster dns -d inlanefreight.com -w /usr/share/seclists/Discovery/DNS/namelist.txt

    ===============================================================
    Gobuster v3.0.1
    by OJ Reeves (@TheColonial) & Christian Mehlmauer (@_FireFart_)
    ===============================================================
    [+] Domain:     inlanefreight.com
    [+] Threads:    10
    [+] Timeout:    1s
    [+] Wordlist:   /usr/share/seclists/Discovery/DNS/namelist.txt
    ===============================================================
    2020/12/17 23:08:55 Starting gobuster
    ===============================================================
    Found: blog.inlanefreight.com
    Found: customer.inlanefreight.com
    Found: my.inlanefreight.com
    Found: ns1.inlanefreight.com
    Found: ns2.inlanefreight.com
    Found: ns3.inlanefreight.com
    ===============================================================
    2020/12/17 23:10:34 Finished
    ===============================================================

## Fuzzing

The [Attacking Web Applications with Ffuf](https://academy.hackthebox.com/module/details/54) module goes into more details about web enumeration and fuzzing

## Banner Grabbing / Web Server Headers

Web server headers provide a good picture of what is hosted on a web server. They can reveal the specific application framework in use, the authentication options, and whether the server is missing essential security options or has been misconfigured. We can use cURL to retrieve server header information from the command line.

    $ curl -IL https://www.inlanefreight.com

    HTTP/1.1 200 OK
    Date: Fri, 18 Dec 2020 22:24:05 GMT
    Server: Apache/2.4.29 (Ubuntu)
    Link: <https://www.inlanefreight.com/index.php/wp-json/>; rel="https://api.w.org/"
    Link: <https://www.inlanefreight.com/>; rel=shortlink
    Content-Type: text/html; charset=UTF-8

Another handy tool is [EyeWitness](https://github.com/FortyNorthSecurity/EyeWitness), which can be used to take screenshots of target web applications, fingerprint them, and identify possible default credentials.

We can extract the version of web servers, supporting frameworks, and applications using the command-line tool **whatweb**. This information can help us pinpoint the technologies in use and begin to search for potential vulnerabilities.

    $ whatweb 10.10.10.121

    http://10.10.10.121 [200 OK] Apache[2.4.41], Country[RESERVED][ZZ], Email[license@php.net], HTTPServer[Ubuntu Linux][Apache/2.4.41 (Ubuntu)], IP[10.10.10.121], Title[PHP 7.4.3 - phpinfo()]

## Certificates

SSL/TLS certificates are another potentially valuable source of information if HTTPS is in use. The certificate can reveal details, including the email address and company name. These could potentially be used to conduct a phishing attack if this is within the scope of an assessment.

## robots.txt

It is common for websites to contain a **robots.txt** file, whose purpose is to instruct search engine web crawlers such as Googlebot which resources can and cannot be accessed for indexing. The **robots.txt** file can provide valuable information such as the location of private files and admin pages.

## Source Code

It is also worth checking the source code for any web pages we come across. We can hit **ctrl+u** to bring up the source code window in a browser.
